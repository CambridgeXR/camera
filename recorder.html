<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Presentation Recorder</title>
<style>
  :root{--bg:#0b1120;--panel:#121a2b;--ink:#e7ecff;--muted:#a2acc4;--accent:#7aa2ff;--ok:#67f79a;--warn:#ffd166;--bad:#ff6b6b}
  html,body{margin:0;background:var(--bg);color:var(--ink);font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif}
  .wrap{max-width:1100px;margin:24px auto;padding:0 16px}
  h1{margin:0 0 12px;font-size:22px}
  .grid{display:grid;grid-template-columns:1.2fr .8fr;gap:16px}
  @media (max-width:900px){.grid{grid-template-columns:1fr}}
  .card{background:var(--panel);border-radius:14px;padding:12px;box-shadow:0 8px 30px rgba(0,0,0,.35)}
  .area{position:relative;aspect-ratio:16/9;background:#000;border-radius:12px;overflow:hidden}
  video,canvas{position:absolute;inset:0;width:100%;height:100%;object-fit:cover}
  .bar{display:flex;gap:8px;align-items:center;flex-wrap:wrap;margin-top:10px}
  select,button,a.btn{background:#0f1627;border:1px solid #26304a;color:var(--ink);padding:8px 12px;border-radius:10px;font-size:14px;text-decoration:none;display:inline-flex;align-items:center;gap:6px}
  button{cursor:pointer}
  button.primary{background:var(--accent);color:#0b0f1d;border:none}
  button.danger{background:var(--bad);color:#1b0b0b;border:none}
  button:disabled,select:disabled{opacity:.6;cursor:not-allowed}
  .result{display:flex;align-items:center;gap:10px;padding:10px;border-radius:10px;background:#0f1627;border:1px solid #26304a}
  .score{font-size:28px;font-weight:800}
  .tag{font-size:12px;padding:2px 8px;border-radius:8px;background:#1a2440;border:1px solid #2a3560}
  .dot{width:8px;height:8px;border-radius:50%;display:inline-block;background:#7683a8}
  .dot.live{background:#ff5a5a;box-shadow:0 0 0 6px rgba(255,90,90,.15)}
  .water{position:absolute;right:10px;bottom:10px;font-size:11px;padding:6px 8px;border-radius:999px;background:rgba(0,0,0,.45);border:1px solid rgba(255,255,255,.08)}
  .err{background:#2a1120;border:1px solid #ff6b6b;color:#ffd3d3;padding:8px 10px;border-radius:10px;display:none;white-space:pre-line}
  .hint{font-size:12px;color:#a2acc4}
  .progress{height:8px;background:#26304a;border-radius:999px;overflow:hidden;flex:1}
  .progress>span{display:block;height:100%;width:0%;background:#7aa2ff;transition:width .1s linear}
</style>
<!-- Stable TFJS + BlazeFace -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>
</head>
<body>
<div class="wrap">
  <h1>🎤 Presentation Recorder</h1>
  <div class="grid">
    <!-- Live + controls -->
    <div class="card">
      <div class="area">
        <video id="preview" playsinline autoplay muted></video>
        <canvas id="overlay"></canvas>
        <div class="water"><span id="liveDot" class="dot"></span> Live</div>
      </div>
      <div class="bar">
        <select id="camera"></select>
        <select id="microphone"></select>
        <label style="display:inline-flex;align-items:center;gap:6px"><input type="checkbox" id="mirror"> Mirror</label>
        <span class="tag" id="perm">Permissions: not requested</span>
      </div>
      <div class="bar">
        <button id="enable" class="primary">Enable camera & mic</button>
        <button id="start" disabled>Start</button>
        <button id="pause" disabled>Pause</button>
        <button id="resume" disabled>Resume</button>
        <button id="stop" class="danger" disabled>Stop</button>
        <a id="download" class="btn" download="practice.webm" style="display:none">Download</a>
        <span class="tag" id="timer">00:00</span>
      </div>
      <div id="err" class="err"></div>
      <div class="hint" id="hint" style="margin-top:6px;display:none"></div>
    </div>

    <!-- Playback + analysis -->
    <div class="card">
      <div class="area" style="background:#05070f">
        <video id="playback" controls playsinline></video>
        <div class="water">Recorded</div>
      </div>
      <div class="bar">
        <button id="analyze" disabled>Analyze Eye Contact</button>
        <div class="progress"><span id="prog"></span></div>
        <span class="tag" id="progText">0%</span>
      </div>
      <div class="bar">
        <div class="result" style="flex:1">
          <div>Eye contact</div>
          <div class="score" id="score">—%</div>
          <div class="mini" id="scoreDetail">no analysis yet</div>
        </div>
      </div>
      <div class="hint">
        Eye Contact % is computed after recording by sampling frames when one face is roughly front-facing (your data is not shared with anyone).
      </div>
    </div>
  </div>
</div>

<script>
(() => {
  // ---------- Elements ----------
  const v = document.getElementById('preview');
  const pb = document.getElementById('playback');
  const cv = document.getElementById('overlay');
  const cx = cv.getContext('2d');
  const camSel = document.getElementById('camera');
  const micSel = document.getElementById('microphone');
  const mirror = document.getElementById('mirror');
  const perm = document.getElementById('perm');
  const enableBtn = document.getElementById('enable');
  const startBtn = document.getElementById('start');
  const pauseBtn = document.getElementById('pause');
  const resumeBtn = document.getElementById('resume');
  const stopBtn = document.getElementById('stop');
  const downloadLink = document.getElementById('download');
  const timerEl = document.getElementById('timer');
  const errBox = document.getElementById('err');
  const hint = document.getElementById('hint');
  const liveDot = document.getElementById('liveDot');
  const analyzeBtn = document.getElementById('analyze');
  const progBar = document.getElementById('prog');
  const progText = document.getElementById('progText');
  const scoreEl = document.getElementById('score');
  const scoreDetail = document.getElementById('scoreDetail');

  // ---------- State ----------
  let stream=null, mediaRecorder=null, chunks=[];
  let recording=false, paused=false;
  let blazeModel=null;
  let tIv=null, tStart=0;

  // ---------- Utils ----------
  function showErr(msg){ errBox.textContent = msg; errBox.style.display = 'block'; }
  function clearErr(){ errBox.style.display='none'; errBox.textContent=''; }
  function fmt(s){ const m=Math.floor(s/60).toString().padStart(2,'0'); const x=Math.floor(s%60).toString().padStart(2,'0'); return `${m}:${x}`; }
  function startTimer(){ tStart=Date.now(); timerEl.textContent='00:00'; if(tIv) clearInterval(tIv); tIv=setInterval(()=>{ timerEl.textContent=fmt((Date.now()-tStart)/1000) },200); }
  function stopTimer(){ if(tIv) clearInterval(tIv); tIv=null; }
  function setCanvasSize(){ const w=v.videoWidth||cv.clientWidth, h=v.videoHeight||cv.clientHeight; if(w&&h){ cv.width=w; cv.height=h; } }

  // ---------- Devices & stream ----------
  async function listDevices(){
    const devs = await navigator.mediaDevices.enumerateDevices();
    const cams = devs.filter(d=>d.kind==='videoinput');
    const mics = devs.filter(d=>d.kind==='audioinput');
    camSel.innerHTML = cams.map(d=>`<option value="${d.deviceId}">${d.label||'Camera'}</option>`).join('') || '<option>No camera</option>';
    micSel.innerHTML = mics.map(d=>`<option value="${d.deviceId}">${d.label||'Microphone'}</option>`).join('') || '<option>No mic</option>';
  }

  // Robust permissions: try AV, fall back to video-only
  async function requestPermissionsRobust() {
    perm.textContent='Permissions: requesting…';
    try{
      const pre = await navigator.mediaDevices.getUserMedia({ video:true, audio:true });
      pre.getTracks().forEach(t=>t.stop());
      return {video:true, audio:true};
    }catch(e1){
      try{
        const pre2 = await navigator.mediaDevices.getUserMedia({ video:true, audio:false });
        pre2.getTracks().forEach(t=>t.stop());
        hint.style.display='block';
        hint.textContent='Microphone access failed or is blocked. Continuing with camera-only.';
        return {video:true, audio:false};
      }catch(e2){
        throw e1;
      }
    }
  }

  async function startStream(wantAudio=true){
    if(stream) stream.getTracks().forEach(t=>t.stop());
    const constraints = {
      video: { deviceId: camSel.value? {exact:camSel.value}:undefined, width:{ideal:1280}, height:{ideal:720} },
      audio: wantAudio ? { deviceId: micSel.value? {exact:micSel.value}:undefined, echoCancellation:true, noiseSuppression:true, autoGainControl:true } : false
    };
    stream = await navigator.mediaDevices.getUserMedia(constraints);
    v.srcObject = stream; v.muted = true; await v.play();
    liveDot.classList.add('live');
    setCanvasSize();
    drawGuide();
  }

  // ---------- Recorder ----------
  function setupRecorder(){
    chunks.length=0;
    const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')?'video/webm;codecs=vp9,opus':
                 MediaRecorder.isTypeSupported('video/webm;codecs=vp8,opus')?'video/webm;codecs=vp8,opus':'video/webm';
    mediaRecorder = new MediaRecorder(stream,{mimeType:mime, videoBitsPerSecond:4_000_000});
    mediaRecorder.ondataavailable = e=>{ if(e.data && e.data.size) chunks.push(e.data); };
    mediaRecorder.onstop = ()=>{
      const blob = new Blob(chunks,{type: mediaRecorder.mimeType});
      const url = URL.createObjectURL(blob);
      pb.src = url;
      downloadLink.href = url;
      downloadLink.style.display='inline-flex';
      downloadLink.download = `presentation-${new Date().toISOString().replace(/[:.]/g,'-')}.webm`;
      analyzeBtn.disabled = false; // can analyze now
    };
  }

  // ---------- Overlay guide ----------
  function drawGuide(){
    requestAnimationFrame(drawGuide);
    if(!v || v.readyState < 2) return;
    setCanvasSize();
    const W=cv.width, H=cv.height;
    cx.clearRect(0,0,W,H);
    cx.save();
    if(mirror.checked){ cx.translate(W,0); cx.scale(-1,1); }
    cx.strokeStyle='rgba(122,162,255,0.5)'; cx.lineWidth=2;
    const gx=W*0.28, gy=H*0.25, gw=W*0.44, gh=H*0.5;
    cx.strokeRect(gx,gy,gw,gh);
    cx.restore();
  }
  mirror.addEventListener('change', ()=>{ v.style.transform = mirror.checked? 'scaleX(-1)':'none'; });

  // ---------- Eye contact (post-recording) ----------
  // Infinity-duration fix: force Chrome to compute duration by jumping far ahead, then back.
  async function loadVideoForAnalysis(src){
    return new Promise((resolve, reject)=>{
      const av = document.createElement('video');
      av.preload = 'auto';
      av.muted = true;
      av.playsInline = true;
      av.src = src;

      const finish = ()=>{
        if (!isFinite(av.duration) || av.duration <= 0) {
          reject(new Error('Could not read video duration.'));
        } else {
          resolve(av);
        }
      };

      av.addEventListener('loadedmetadata', async ()=>{
        if (isFinite(av.duration) && av.duration > 0 && av.duration !== Infinity) {
          finish();
        } else {
          // Force duration to resolve
          const onTimeUpdate = ()=>{
            av.removeEventListener('timeupdate', onTimeUpdate);
            av.currentTime = 0;
            setTimeout(finish, 0);
          };
          av.addEventListener('timeupdate', onTimeUpdate);
          try { av.currentTime = 1e101; } catch(_) { /* some builds require play() */ }
          try { av.play().then(()=>{ av.pause(); }).catch(()=>{}); } catch(_){}
        }
      }, {once:true});

      av.addEventListener('error', ()=> reject(new Error('Video could not be loaded.')), {once:true});
    });
  }

  function facingHeuristic(face, W, H){
    const [x1,y1]=face.topLeft, [x2,y2]=face.bottomRight;
    const cx=(x1+x2)/2, cy=(y1+y2)/2;
    const areaRatio=((x2-x1)*(y2-y1))/(W*H);
    const centerOk = (cx > W*0.28 && cx < W*0.72 && cy > H*0.25 && cy < H*0.75);
    const sizeOk   = areaRatio > 0.035;

    const Reye=face.landmarks[0], Leye=face.landmarks[1], Nose=face.landmarks[2], Rear=face.landmarks[4], Lear=face.landmarks[5];
    const eyeDist = Math.hypot(Leye[0]-Reye[0], Leye[1]-Reye[1]) || 1;
    const eyesLevel = Math.abs(Leye[1]-Reye[1]) / eyeDist < 0.18;
    const dNL = Math.hypot(Nose[0]-Lear[0], Nose[1]-Lear[1]);
    const dNR = Math.hypot(Nose[0]-Rear[0], Nose[1]-Rear[1]);
    const yawSkew = Math.abs(dNL - dNR) / ((dNL + dNR)/2 || 1);
    const yawOk = yawSkew < 0.30;
    const eyeMidY = (Leye[1]+Reye[1])/2;
    const pitch = Math.abs(Nose[1]-eyeMidY) / ((y2-y1) || 1);
    const pitchOk = pitch < 0.35;

    return centerOk && sizeOk && eyesLevel && yawOk && pitchOk;
  }

  async function analyzeEyeContact(videoURL){
    if(!videoURL){ throw new Error('No video to analyze.'); }

    // Load model once
    if(!blazeModel){
      await tf.setBackend('webgl'); // performance
      blazeModel = await blazeface.load();
    }

    // Load and fix duration
    const av = await loadVideoForAnalysis(videoURL);

    // Use the actual video dimensions
    const W = av.videoWidth || 1280;
    const H = av.videoHeight || 720;
    const off = document.createElement('canvas'); off.width=W; off.height=H;
    const ox = off.getContext('2d');

    const duration = av.duration;
    const targetFPS = 4;                 // ~4 fps sampling
    const totalSteps = Math.max(1, Math.floor(duration * targetFPS));
    let total=0, facing=0;

    for(let i=0;i<totalSteps;i++){
      const t = Math.min(duration - 0.05, (i/targetFPS));
      await new Promise((resolve)=>{
        const onSeek = ()=>{ av.removeEventListener('seeked', onSeek); resolve(); };
        av.addEventListener('seeked', onSeek);
        av.currentTime = t;
      });

      ox.drawImage(av, 0, 0, W, H);
      const preds = await blazeModel.estimateFaces(off, false);
      total++;
      if(preds && preds.length===1){
        if(facingHeuristic(preds[0], W, H)) facing++;
      }

      const pct = Math.round((i+1)/totalSteps*100);
      progBar.style.width = pct + '%';
      progText.textContent = pct + '%';
    }

    const percent = total ? Math.round((facing/total)*100) : 0;
    scoreEl.textContent = percent + '%';
    scoreEl.style.color = percent>=70? 'var(--ok)' : percent>=40? 'var(--warn)' : 'var(--bad)';
    scoreDetail.textContent = `${facing} of ${total} sampled frames (~${targetFPS} fps)`;
  }

  // ---------- Handlers ----------
  enableBtn.addEventListener('click', async ()=>{
    clearErr();
    try{
      const got = await requestPermissionsRobust();  // prompts on click
      await listDevices();                           // labels after permission
      await startStream(!!got.audio);                // start stream
      perm.textContent='Permissions: granted';
      enableBtn.disabled=true;
      startBtn.disabled=false;
    }catch(e){
      console.error(e);
      perm.textContent='Permissions: denied';
      let msg = 'Unable to access camera/microphone.\n\n';
      if(e && e.name==='NotAllowedError'){
        msg += 'Access was blocked.\nChrome: lock icon → Site settings → Allow Camera & Microphone for cambridgexr.github.io → refresh.';
      } else if(e && e.name==='NotFoundError'){
        msg += 'No camera/microphone found. Connect a device and try again.';
      } else if(e && e.name==='NotReadableError'){
        msg += 'Your camera/mic is in use by another app. Close it and retry.';
      } else if(e && e.name==='OverconstrainedError'){
        msg += 'Selected device not available. Choose another camera/mic.';
      } else {
        msg += (e && e.message) ? e.message : String(e);
      }
      showErr(msg);
      hint.style.display='block';
      hint.textContent='Windows tip: Settings → Privacy & security → Camera/Microphone → allow access for browsers.';
    }
  });

  camSel.addEventListener('change', async ()=>{ try{ await startStream(true); }catch(e){ try{ await startStream(false); }catch(_){}} });
  micSel.addEventListener('change', async ()=>{ try{ await startStream(true); }catch(e){ hint.style.display='block'; hint.textContent='That microphone failed; continuing with camera-only.'; await startStream(false); } });

  startBtn.addEventListener('click', ()=>{
    if(!stream){ showErr('Click “Enable camera & mic” first.'); return; }
    setupRecorder();
    mediaRecorder.start();
    recording=true; paused=false;
    startBtn.disabled=true; stopBtn.disabled=false; pauseBtn.disabled=false; resumeBtn.disabled=true;
    startTimer();
  });

  pauseBtn.addEventListener('click', ()=>{ if(mediaRecorder && mediaRecorder.state==='recording'){ mediaRecorder.pause(); paused=true; pauseBtn.disabled=true; resumeBtn.disabled=false; }});
  resumeBtn.addEventListener('click', ()=>{ if(mediaRecorder && mediaRecorder.state==='paused'){ mediaRecorder.resume(); paused=false; pauseBtn.disabled=false; resumeBtn.disabled=true; }});
  stopBtn.addEventListener('click', ()=>{
    if(mediaRecorder && (mediaRecorder.state==='recording' || mediaRecorder.state==='paused')){
      mediaRecorder.stop(); recording=false; paused=false;
      stopBtn.disabled=true; pauseBtn.disabled=true; resumeBtn.disabled=true; startBtn.disabled=false;
      stopTimer();
    }
  });

  analyzeBtn.addEventListener('click', async ()=>{
    clearErr();
    try{
      analyzeBtn.disabled = true;
      progBar.style.width = '0%';
      progText.textContent = '0%';
      scoreEl.textContent = '—%';
      scoreDetail.textContent = 'analyzing…';
      await analyzeEyeContact(pb.src);
      analyzeBtn.disabled = false;
    }catch(e){
      console.error(e);
      analyzeBtn.disabled = false;
      showErr('Analysis failed: ' + (e && e.message ? e.message : e));
    }
  });

  pb.addEventListener('loadeddata', ()=>{ if(pb.src) analyzeBtn.disabled=false; });

  // Early checks
  (function(){
    if(!('mediaDevices' in navigator) || !('getUserMedia' in navigator.mediaDevices)){
      perm.textContent='Unsupported browser';
      showErr('Your browser does not support camera/microphone (no navigator.mediaDevices.getUserMedia). Use latest Chrome/Edge/Firefox.');
    }
    if(typeof MediaRecorder==='undefined'){
      showErr('Recording is not supported in this browser.');
    }
  })();
})();
</script>
</body>
</html>
