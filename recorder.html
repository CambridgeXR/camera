<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Presentation Recorder</title>
<style>
  :root{--bg:#0b1120;--panel:#121a2b;--ink:#e7ecff;--muted:#a2acc4;--accent:#7aa2ff;--ok:#67f79a;--warn:#ffd166;--bad:#ff6b6b}
  html,body{margin:0;background:var(--bg);color:var(--ink);font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,sans-serif}
  .wrap{max-width:1100px;margin:24px auto;padding:0 16px}
  h1{margin:0 0 12px;font-size:22px}
  .grid{display:grid;grid-template-columns:1.2fr .8fr;gap:16px}
  @media (max-width:900px){.grid{grid-template-columns:1fr}}
  .card{background:var(--panel);border-radius:14px;padding:12px;box-shadow:0 8px 30px rgba(0,0,0,.35)}
  .area{position:relative;aspect-ratio:16/9;background:#000;border-radius:12px;overflow:hidden}
  video,canvas{position:absolute;inset:0;width:100%;height:100%;object-fit:cover}
  .bar{display:flex;gap:8px;align-items:center;flex-wrap:wrap;margin-top:10px}
  select,button,a.btn{background:#0f1627;border:1px solid #26304a;color:var(--ink);padding:8px 12px;border-radius:10px;font-size:14px;text-decoration:none;display:inline-flex;align-items:center;gap:6px}
  button{cursor:pointer}
  button.primary{background:var(--accent);color:#0b0f1d;border:none}
  button.danger{background:var(--bad);color:#1b0b0b;border:none}
  button:disabled,select:disabled{opacity:.6;cursor:not-allowed}
  .result{display:flex;align-items:center;gap:10px;padding:10px;border-radius:10px;background:#0f1627;border:1px solid #26304a}
  .score{font-size:28px;font-weight:800}
  .tag{font-size:12px;padding:2px 8px;border-radius:8px;background:#1a2440;border:1px solid #2a3560}
  .dot{width:8px;height:8px;border-radius:50%;display:inline-block;background:#7683a8}
  .dot.live{background:#ff5a5a;box-shadow:0 0 0 6px rgba(255,90,90,.15)}
  .water{position:absolute;right:10px;bottom:10px;font-size:11px;padding:6px 8px;border-radius:999px;background:rgba(0,0,0,.45);border:1px solid rgba(255,255,255,.08)}
  .err{background:#2a1120;border:1px solid #ff6b6b;color:#ffd3d3;padding:8px 10px;border-radius:10px;display:none;white-space:pre-line}
  .hint{font-size:12px;color:var(--muted)}
  .progress{height:8px;background:#26304a;border-radius:999px;overflow:hidden;flex:1}
  .progress>span{display:block;height:100%;width:0%;background:#7aa2ff;transition:width .1s linear}
</style>
<!-- Stable TFJS + BlazeFace (model hosted by Google) -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.14.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.0.7/dist/blazeface.min.js"></script>
</head>
<body>
<div class="wrap">
  <h1>🎤 Presentation Recorder</h1>
  <div class="grid">
    <!-- Left: live preview + controls -->
    <div class="card">
      <div class="area">
        <video id="preview" playsinline autoplay muted></video>
        <canvas id="overlay"></canvas>
        <div class="water"><span id="liveDot" class="dot"></span> Live</div>
      </div>
      <div class="bar">
        <select id="camera"></select>
        <select id="microphone"></select>
        <label style="display:inline-flex;align-items:center;gap:6px">
          <input type="checkbox" id="mirror"> Mirror
        </label>
        <span class="tag" id="perm">Permissions: not requested</span>
      </div>
      <div class="bar">
        <button id="enable" class="primary">Enable camera & mic</button>
        <button id="start" disabled>Start</button>
        <button id="pause" disabled>Pause</button>
        <button id="resume" disabled>Resume</button>
        <button id="stop" class="danger" disabled>Stop</button>
        <a id="download" class="btn" download="practice.webm" style="display:none">Download</a>
        <span class="tag" id="timer">00:00</span>
      </div>
      <div id="err" class="err"></div>
      <div class="hint" id="hint" style="margin-top:6px;display:none"></div>
    </div>

    <!-- Right: playback + analysis -->
    <div class="card">
      <div class="area" style="background:#05070f">
        <video id="playback" controls playsinline></video>
        <div class="water">Recorded</div>
      </div>
      <div class="bar">
        <button id="analyze" disabled>Analyze Eye Contact</button>
        <div class="progress"><span id="prog"></span></div>
        <span class="tag" id="progText">0%</span>
      </div>
      <div class="bar">
        <div class="result" style="flex:1">
          <div>Eye contact</div>
          <div class="score" id="score">—%</div>
          <div class="mini" id="scoreDetail">no analysis yet</div>
        </div>
      </div>
      <div class="hint">
        Eye Contact % is computed after recording by sampling frames when one face is centered and appears front-facing.
      </div>
    </div>
  </div>
</div>

<script>
(() => {
  // ------ Elements
  const v = document.getElementById('preview');
  const pb = document.getElementById('playback');
  const cv = document.getElementById('overlay');
  const cx = cv.getContext('2d');
  const camSel = document.getElementById('camera');
  const micSel = document.getElementById('microphone');
  const mirror = document.getElementById('mirror');
  const perm = document.getElementById('perm');
  const enableBtn = document.getElementById('enable');
  const startBtn = document.getElementById('start');
  const pauseBtn = document.getElementById('pause');
  const resumeBtn = document.getElementById('resume');
  const stopBtn = document.getElementById('stop');
  const downloadLink = document.getElementById('download');
  const timerEl = document.getElementById('timer');
  const errBox = document.getElementById('err');
  const hint = document.getElementById('hint');
  const liveDot = document.getElementById('liveDot');
  const analyzeBtn = document.getElementById('analyze');
  const progBar = document.getElementById('prog');
  const progText = document.getElementById('progText');
  const scoreEl = document.getElementById('score');
  const scoreDetail = document.getElementById('scoreDetail');

  // ------ State
  let stream=null, mediaRecorder=null, chunks=[];
  let recording=false, paused=false;
  let tIv=null, tStart=0;

  // BlazeFace model
  let blazeModel=null;

  // ------ Utils
  function showErr(msg){ errBox.textContent = msg; errBox.style.display = 'block'; }
  function clearErr(){ errBox.style.display='none'; errBox.textContent=''; }
  function fmt(s){ const m=Math.floor(s/60).toString().padStart(2,'0'); const x=Math.floor(s%60).toString().padStart(2,'0'); return `${m}:${x}`; }
  function startTimer(){ tStart=Date.now(); timerEl.textContent='00:00'; if(tIv) clearInterval(tIv); tIv=setInterval(()=>{ timerEl.textContent=fmt((Date.now()-tStart)/1000) },200); }
  function stopTimer(){ if(tIv) clearInterval(tIv); tIv=null; }
  function setCanvasSize(){ const w=v.videoWidth||cv.clientWidth, h=v.videoHeight||cv.clientHeight; if(w&&h){ cv.width=w; cv.height=h; } }

  // ------ Device & Stream
  async function listDevices(){
    const devs = await navigator.mediaDevices.enumerateDevices();
    const cams = devs.filter(d=>d.kind==='videoinput');
    const mics = devs.filter(d=>d.kind==='audioinput');
    camSel.innerHTML = cams.map(d=>`<option value="${d.deviceId}">${d.label||'Camera'}</option>`).join('') || '<option>No camera</option>';
    micSel.innerHTML = mics.map(d=>`<option value="${d.deviceId}">${d.label||'Microphone'}</option>`).join('') || '<option>No mic</option>';
  }

  async function preflightPermissions(){
    perm.textContent = 'Permissions: requesting…';
    const pre = await navigator.mediaDevices.getUserMedia({ video:true, audio:true });
    pre.getTracks().forEach(t=>t.stop());
  }

  async function startStream(){
    if(stream) stream.getTracks().forEach(t=>t.stop());
    stream = await navigator.mediaDevices.getUserMedia({
      video: { deviceId: camSel.value? {exact:camSel.value}:undefined, width:{ideal:1280}, height:{ideal:720} },
      audio: { deviceId: micSel.value? {exact:micSel.value}:undefined, echoCancellation:true, noiseSuppression:true, autoGainControl:true }
    });
    v.srcObject = stream; v.muted = true; await v.play();
    liveDot.classList.add('live');
    setCanvasSize();
    drawGuide(); // draw guide box for centering
  }

  // ------ Recorder
  function setupRecorder(){
    chunks.length=0;
    const mime = MediaRecorder.isTypeSupported('video/webm;codecs=vp9,opus')?'video/webm;codecs=vp9,opus':
                 MediaRecorder.isTypeSupported('video/webm;codecs=vp8,opus')?'video/webm;codecs=vp8,opus':'video/webm';
    mediaRecorder = new MediaRecorder(stream,{mimeType:mime, videoBitsPerSecond:4_000_000});
    mediaRecorder.ondataavailable = e=>{ if(e.data && e.data.size) chunks.push(e.data); };
    mediaRecorder.onstop = ()=>{
      const blob = new Blob(chunks,{type: mediaRecorder.mimeType});
      const url = URL.createObjectURL(blob);
      pb.src = url;
      downloadLink.href = url;
      downloadLink.style.display='inline-flex';
      downloadLink.download = `presentation-${new Date().toISOString().replace(/[:.]/g,'-')}.webm`;
      analyzeBtn.disabled = false; // enable analysis now that we have a recording
    };
  }

  // ------ Live overlay guide (just a rectangle to help centering)
  function drawGuide(){
    requestAnimationFrame(drawGuide);
    if(!v || v.readyState < 2) return;
    setCanvasSize();
    const W=cv.width, H=cv.height;
    cx.clearRect(0,0,W,H);
    cx.save();
    if(mirror.checked){ cx.translate(W,0); cx.scale(-1,1); }
    cx.strokeStyle='rgba(122,162,255,0.5)'; cx.lineWidth=2;
    // center “acceptable” zone
    const gx=W*0.28, gy=H*0.25, gw=W*0.44, gh=H*0.5;
    cx.strokeRect(gx,gy,gw,gh);
    cx.restore();
  }

  // ------ Eye-contact heuristics (BlazeFace landmarks)
  function facingHeuristic(face, W, H){
    // Inputs: face.topLeft, face.bottomRight, face.landmarks: [rightEye, leftEye, nose, mouth, rightEar, leftEar]
    const [x1,y1]=face.topLeft, [x2,y2]=face.bottomRight;
    const cx=(x1+x2)/2, cy=(y1+y2)/2;
    const areaRatio=((x2-x1)*(y2-y1))/(W*H);
    const centerOk = (cx > W*0.28 && cx < W*0.72 && cy > H*0.25 && cy < H*0.75);
    const sizeOk   = areaRatio > 0.035;

    const Reye=face.landmarks[0], Leye=face.landmarks[1], Nose=face.landmarks[2], Rear=face.landmarks[4], Lear=face.landmarks[5];

    // Eyes roughly level
    const eyeDist = Math.hypot(Leye[0]-Reye[0], Leye[1]-Reye[1]) || 1;
    const eyesLevel = Math.abs(Leye[1]-Reye[1]) / eyeDist < 0.18;

    // Yaw ~ nose centered between ears
    const dNL = Math.hypot(Nose[0]-Lear[0], Nose[1]-Lear[1]);
    const dNR = Math.hypot(Nose[0]-Rear[0], Nose[1]-Rear[1]);
    const yawSkew = Math.abs(dNL - dNR) / ((dNL + dNR)/2 || 1);
    const yawOk = yawSkew < 0.30;

    // Pitch ~ nose near eye-line vertically relative to box height
    const eyeMidY = (Leye[1]+Reye[1])/2;
    const pitch = Math.abs(Nose[1]-eyeMidY) / ((y2-y1) || 1);
    const pitchOk = pitch < 0.35;

    return centerOk && sizeOk && eyesLevel && yawOk && pitchOk;
  }

  // ------ Offline analyzer (runs AFTER recording)
  async function analyzeEyeContact(videoURL){
    // Load model once
    if(!blazeModel){
      // Ensure WebGL backend for speed
      await tf.setBackend('webgl');
      blazeModel = await blazeface.load(); // model + weights fetched from Google's tfjs-models storage
    }

    // Hidden video for seeking frames
    const av = document.createElement('video');
    av.src = videoURL;
    av.crossOrigin = 'anonymous';
    av.muted = true; // avoid autoplay warnings
    av.playsInline = true;

    await new Promise(res=> av.onloadedmetadata=res);
    const duration = av.duration || 0;
    if(!duration || !isFinite(duration)){ throw new Error('Could not read video duration.'); }

    const W = pb.videoWidth || 1280, H = pb.videoHeight || 720;
    const off = document.createElement('canvas');
    off.width = W; off.height = H;
    const ox = off.getContext('2d');

    const targetFPS = 4;                // sample 4 frames per second
    const step = 1/targetFPS;
    let total=0, facing=0;

    for(let t=0; t<duration; t+=step){
      // Seek and wait
      await new Promise((resolve)=>{
        const onSeek = ()=>{ av.removeEventListener('seeked', onSeek); resolve(); };
        av.addEventListener('seeked', onSeek);
        av.currentTime = Math.min(t, duration - 0.05);
      });

      // Draw frame to offscreen canvas
      ox.drawImage(av, 0, 0, W, H);

      // Run face detection
      const preds = await blazeModel.estimateFaces(off, false);
      total++;

      if(preds && preds.length===1){
        if(facingHeuristic(preds[0], W, H)) facing++;
      }

      // Progress UI
      const pct = Math.round(Math.min(100, (t/duration)*100));
      progBar.style.width = pct + '%';
      progText.textContent = pct + '%';
    }

    // Finish
    progBar.style.width = '100%';
    progText.textContent = '100%';

    const percent = total ? Math.round((facing/total)*100) : 0;
    scoreEl.textContent = percent + '%';
    scoreEl.style.color = percent>=70? 'var(--ok)' : percent>=40? 'var(--warn)' : 'var(--bad)';
    scoreDetail.textContent = `${facing} of ${total} sampled frames (~${targetFPS} fps)`;
  }

  // ------ UI wiring
  mirror.addEventListener('change', ()=>{ v.style.transform = mirror.checked? 'scaleX(-1
